{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz, export_text\n",
    "\n",
    "from autotm.params import FixedListParams, PipelineParams, iterations_of_type\n",
    "from autotm.schemas import IndividualDTO\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "784a9bbaea65350",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 900\n",
    "sns.set(style=\"whitegrid\")\n",
    "pd.set_option('display.precision', 3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45899bcf7d85b3a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATASET_MAPPING = {\n",
    "    \"20newsgroups_sample\": \"20News Groups\",\n",
    "    \"amazon_food_sample\": \"Amazon Food\",\n",
    "    \"banners_sample\": \"Banners\",\n",
    "    \"hotel-reviews_sample\": \"Hotel Reviews\",\n",
    "    \"lenta_ru_sample\": \"Lenta.ru\",\n",
    "}"
   ],
   "id": "35627fc9028e93bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Collection of the data\n",
    "\n",
    "Firstly we collect the results from all the AutoTM runs"
   ],
   "id": "37008e0592da4772"
  },
  {
   "cell_type": "code",
   "source": [
    "def collect_all_parameters():\n",
    "    base_dir = \"statistics\"\n",
    "    files_in_directory = os.listdir(base_dir)\n",
    "    log_files = [os.path.join(base_dir, file) for file in files_in_directory if re.match(r\".*_parameters.txt\", file)]\n",
    "    print(len(log_files))\n",
    "    params = []\n",
    "    for log_file in log_files:\n",
    "        if \"_surrogate_\" in log_file:\n",
    "            continue\n",
    "        with open(log_file) as file:\n",
    "            params += file.read().splitlines()\n",
    "    return [IndividualDTO.model_validate_json(param) for param in params]\n",
    "\n",
    "\n",
    "all_params = collect_all_parameters()\n",
    "all_params[0].params, all_params[0].dataset"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Feature extraction"
   ],
   "id": "1334d73e4206cf25"
  },
  {
   "cell_type": "code",
   "source": [
    "DATASET_LABEL = 'dataset'\n",
    "SOLUTION_LABEL = 'solution'\n",
    "PIPELINE_LABEL = \"pipeline\"\n",
    "FIXED_SIZE_LABEL = \"fixed-size\"\n",
    "STAGES_NUMBER_LABEL = 'stages'\n",
    "FITNESS_LABEL = \"Fitness\"\n",
    "ITERATIONS_NUMBER_LABEL = 'Iterations'\n",
    "ITERATIONS_DECORRELATION_LABEL = 'Iterations\\ndecorrelation'\n",
    "ITERATIONS_SPARSE_LABEL = 'Iterations\\nsparse'\n",
    "ITERATIONS_SMOOTH_LABEL = 'Iterations\\nsmooth'\n",
    "DECORRELATION_A_LABEL = 'Decorrelation\\na'\n",
    "DECORRELATION_B_LABEL = 'Decorrelation\\nb'\n",
    "SPARSE_A_LABEL = 'Sparse\\na'\n",
    "SPARSE_B_LABEL = 'Sparse\\nb'\n",
    "SMOOTH_A_LABEL = 'Smooth\\na'\n",
    "SMOOTH_B_LABEL = 'Smooth\\nb'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "863aeb92f5b5f06e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def iterations_number(stages):\n",
    "    return sum(stage.values[0] for stage in stages)\n",
    "\n",
    "def avg_param(stages, index):\n",
    "    values = [stage.values[index] for stage in stages]\n",
    "    if len(values) == 0:\n",
    "        return 0\n",
    "    return np.mean(values)\n",
    "\n",
    "def extract_features(dtos: List[IndividualDTO]):\n",
    "    features = defaultdict(list)\n",
    "    for dto in dtos:\n",
    "        features[DATASET_LABEL].append(dto.dataset)\n",
    "        features[FITNESS_LABEL].append(dto.fitness_value[\"avg_coherence_score\"])\n",
    "\n",
    "        if isinstance(dto.params, FixedListParams):\n",
    "            features[SOLUTION_LABEL].append(FIXED_SIZE_LABEL)\n",
    "            params = dto.params.to_pipeline_params()\n",
    "        elif isinstance(dto.params, PipelineParams):\n",
    "            features[SOLUTION_LABEL].append(PIPELINE_LABEL)\n",
    "            params = dto.params\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected type {dto.params}\")\n",
    "\n",
    "        stages = params.pipeline.stages\n",
    "        features[STAGES_NUMBER_LABEL].append(len(stages))\n",
    "        features[ITERATIONS_NUMBER_LABEL].append(iterations_number(stages))\n",
    "        \n",
    "        decorrelation_iterations = iterations_of_type(stages, \"DecorrelatorPhiRegularizer\")\n",
    "        features[ITERATIONS_DECORRELATION_LABEL].append(iterations_number(decorrelation_iterations))\n",
    "        # features[DECORRELATION_A_LABEL].append(avg_param(decorrelation_iterations, 1))\n",
    "        # features[DECORRELATION_B_LABEL].append(avg_param(decorrelation_iterations, 2))\n",
    "        \n",
    "        sparse_iterations = iterations_of_type(stages, \"SparseThetaRegularizer\")\n",
    "        features[ITERATIONS_SPARSE_LABEL].append(iterations_number(sparse_iterations))\n",
    "        # features[SPARSE_A_LABEL].append(avg_param(sparse_iterations, 1))\n",
    "        # features[SPARSE_B_LABEL].append(avg_param(sparse_iterations, 2))\n",
    "        \n",
    "        smooth_iterations = iterations_of_type(stages, \"SmoothThetaRegularizer\")\n",
    "        features[ITERATIONS_SMOOTH_LABEL].append(iterations_number(smooth_iterations))\n",
    "        # features[SMOOTH_A_LABEL].append(avg_param(smooth_iterations, 1))\n",
    "        # features[SMOOTH_B_LABEL].append(avg_param(smooth_iterations, 2))\n",
    "\n",
    "    return pd.DataFrame(features).drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4892a604aa85a4eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df = extract_features(all_params)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71f44d509691144e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "datasets = sorted(df[DATASET_LABEL].unique())\n",
    "features = [f for f in df.columns.tolist() if f not in [DATASET_LABEL, SOLUTION_LABEL, FITNESS_LABEL]]\n",
    "order = sorted(df[SOLUTION_LABEL].unique())"
   ],
   "id": "c9ce124d9c69dc01",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "next(param.params for param in all_params if isinstance(param.params, PipelineParams))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "618f4d5ae77b8463",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [],
   "id": "29df98cc2c6049d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data exploration\n",
    "\n",
    "Here we analyse distributions for all features in all datasets"
   ],
   "id": "d8a4ca0c50393d10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def select(df, dataset, solution=None):\n",
    "    data = df[df[DATASET_LABEL] == dataset]\n",
    "    data = data.drop([DATASET_LABEL], axis=1)\n",
    "    if solution is not None:\n",
    "        data = data[data[SOLUTION_LABEL] == solution]\n",
    "        data = data.drop([SOLUTION_LABEL], axis=1)\n",
    "    return data"
   ],
   "id": "352c1d275a2c4aee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "font_size = 18\n",
    "fig, axs = plt.subplots(len(features), len(datasets), figsize=(3 * len(datasets), 3 * len(features)), sharex='col', sharey='row')\n",
    "for i, dataset in enumerate(datasets):\n",
    "    data = select(df, dataset).sample(frac=1).reset_index(drop=True)\n",
    "    for j, f in enumerate(features):\n",
    "        sns.scatterplot(data, x=FITNESS_LABEL, y=f, ax=axs[j, i], hue=SOLUTION_LABEL, hue_order=order)\n",
    "        axs[j, i].set_xlabel(FITNESS_LABEL, fontsize=font_size)\n",
    "        axs[j, i].set_ylabel(f, fontsize=font_size)\n",
    "        if i != 0 or j != 0:\n",
    "            axs[j, i].get_legend().remove()\n",
    "    axs[0, i].set_title(DATASET_MAPPING[dataset], fontsize=font_size)\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "plt.savefig(f\"feature_analysis.png\")\n",
    "# plt.clf()"
   ],
   "id": "a17581358516bd5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_descision_tree(data):\n",
    "    y = data[FITNESS_LABEL]\n",
    "    X = data.drop(FITNESS_LABEL, axis=1)\n",
    "    feature_names = X.columns\n",
    "    clf = DecisionTreeRegressor(max_depth=3, criterion=\"absolute_error\", min_samples_leaf=100)\n",
    "    model = clf.fit(X.to_numpy(), y.to_numpy())\n",
    "    return model, feature_names.tolist()"
   ],
   "id": "8dbb9c9bc6935430",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for solution in [PIPELINE_LABEL, FIXED_SIZE_LABEL]:\n",
    "    for dataset in datasets:\n",
    "        print(f\"Dataset: {dataset} solution: {solution}\")\n",
    "        data = select(df, dataset, solution)\n",
    "        model, feature_names = build_descision_tree(data)\n",
    "        print(export_text(model, feature_names=[f.replace(\"\\n\", \"_\") for f in feature_names]))"
   ],
   "id": "b826725b9a24a45a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = \"hotel-reviews_sample\"\n",
    "solution = PIPELINE_LABEL\n",
    "\n",
    "data = select(df, dataset, solution)\n",
    "clf, feature_names = build_descision_tree(data)\n",
    "\n",
    "export_graphviz(clf, out_file='tree.dot', feature_names=[f.replace(\"\\n\", \"_\") for f in feature_names],\n",
    "                rounded=True, proportion=False, precision=2, filled=True)\n",
    "!dot -Tpng tree.dot -o tree.png -Gdpi=600\n",
    "Image(filename='tree.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f44d67b2ab787c30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Best solutions analysis\n",
    "\n",
    "For each dataset we take top 10% solutions and analyse their structure"
   ],
   "id": "d9d4c7f2faa4875a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "solution = PIPELINE_LABEL\n",
    "\n",
    "fs = [FITNESS_LABEL] + features\n",
    "fs.remove(ITERATIONS_SPARSE_LABEL) # all equal 0\n",
    "\n",
    "fig, axs = plt.subplots(len(fs), len(datasets), figsize=(3 * len(datasets), 3 * len(fs)), sharex='col', sharey='row')\n",
    "for i, dataset in enumerate(datasets):\n",
    "    data = select(df, dataset, solution)\n",
    "    target_fitness = np.percentile(data[FITNESS_LABEL], 95, axis=0)\n",
    "    data = data[data[FITNESS_LABEL] >= target_fitness]\n",
    "    assert (data[ITERATIONS_SPARSE_LABEL] == 0).all()\n",
    "    for j, f in enumerate(fs):\n",
    "        sns.histplot(data, y=f, ax=axs[j, i])\n",
    "    axs[0, i].set_title(dataset)\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)"
   ],
   "id": "d6e1ea47b41898c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Surrogate learning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b35c01df9543680"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset in datasets:\n",
    "    for solution in [PIPELINE_LABEL, FIXED_SIZE_LABEL]:\n",
    "        print(f\"Dataset: {dataset} solution: {solution}\")\n",
    "        data = select(df, dataset, solution)\n",
    "        y = data[FITNESS_LABEL].to_numpy()\n",
    "        X = data.drop(FITNESS_LABEL, axis=1).to_numpy()\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "        clf = RandomForestRegressor(max_depth=10, min_samples_leaf=10)\n",
    "        model = clf.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"Train R^2: {model.score(X_train, y_train)}\")\n",
    "        print(f\"Test  R^2: {model.score(X_test, y_test)}\")\n",
    "        print()"
   ],
   "id": "f4f6a8e65b8cad2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_all_features(dtos: List[IndividualDTO]):\n",
    "    features = defaultdict(list)\n",
    "    for dto in dtos:\n",
    "        if isinstance(dto.params, FixedListParams):\n",
    "            continue\n",
    "        elif isinstance(dto.params, PipelineParams):\n",
    "            params = dto.params\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected type {dto.params}\")\n",
    "        features[DATASET_LABEL].append(dto.dataset)\n",
    "        features[FITNESS_LABEL].append(dto.fitness_value[\"avg_coherence_score\"])\n",
    "        vector = params.to_vector()\n",
    "        for i, v in enumerate(vector):\n",
    "            features[f\"f_{i}\"].append(v)\n",
    "    return pd.DataFrame(features).drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcfa97ee39b2541e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df = extract_all_features(all_params)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3234dcadbb8108c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for dataset in datasets:\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    data = select(df, dataset)\n",
    "    y = data[FITNESS_LABEL].to_numpy()\n",
    "    X = data.drop(FITNESS_LABEL, axis=1).to_numpy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    clf = RandomForestRegressor(max_depth=10, min_samples_leaf=10)\n",
    "    model = clf.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Train R^2: {model.score(X_train, y_train)}\")\n",
    "    print(f\"Test  R^2: {model.score(X_test, y_test)}\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dfb2dffdd1eef53",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "pca = PCA(n_components=12)\n",
    "pca.fit(df.drop([FITNESS_LABEL, DATASET_LABEL], axis=1).to_numpy())\n",
    "sum(pca.explained_variance_ratio_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74950474ab6479ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "pca.transform(select(df, dataset).drop(FITNESS_LABEL, axis=1).to_numpy())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b710a055582e0b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for dataset in datasets:\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    data = select(df, dataset)\n",
    "    y = data[FITNESS_LABEL].to_numpy()\n",
    "    X = data.drop(FITNESS_LABEL, axis=1).to_numpy()\n",
    "    X = pca.transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    clf = RandomForestRegressor(max_depth=10, min_samples_leaf=10)\n",
    "    model = clf.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Train R^2: {model.score(X_train, y_train)}\")\n",
    "    print(f\"Test  R^2: {model.score(X_test, y_test)}\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ab2eed74e6a40b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "74f3bf5d8bf7643d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
